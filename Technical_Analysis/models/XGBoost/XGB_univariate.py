# -*- coding: utf-8 -*-
"""XGBSDTA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NGtiNp9DfUybkrSxZlRJIwWFZ3umVMRp
"""

import pandas as pd
import numpy as np
from pandas_datareader import data as pdr
import yfinance as yf
from ta.utils import dropna
import datetime as dt
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
'''
Time Series to Supervised learning
Multi step Univariate forecasting i.e. only feature is the lagged closes of days before 
 - play with lag try one quarter of every day, next quarter every week close, every other quarter monthly closes and other options
Try Another multivariate model using rsi, ema, and macd
 - Look for other good indicators to use beyond those three such as dow, competitor companies, silicon etfs, etc.

https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/ for above

Create a function that executes buy/sell/hold commands based on xgboost confidence and predicted close * Ask dimakis could this be a full on classifier that incorporates other features like sentiment
Create an evaluator that shows the metrics of each different model
https://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/


'''

class XGB_Univariate:
    
    def __init__(self):
        #Needs input of which variables so can be expanded to uni/multivariate maybe list of feature names to get from data
        yf.pdr_override()
        self.stock_data = pdr.get_data_yahoo("TXN") #consider saving somewhere and not downloading every time and to include which features from  list
        self.stock_data = self.stock_data.iloc[12000:]
        self.supervised_data = self.create_supervised_data()
        



    def evaluate(self, n_test): #needs batch size and num features
        predictions = list()
        
        train, test = self.train_test_split(self.supervised_data, n_test) #can be a better call
        history = [x for x in train]

        for i in range(len(test)):
            testX, testy = test[i, :-1], test[i, -1]
            pred = self.forecast(history, testX)
            predictions.append(pred)
            history.append(test[i])
        
       

        return predictions, test[:, -1]

    def forecast(self, train, testX):
        train = np.asarray(train)
        trainX, trainy = train[:, :-1], train[:, -1]

        model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000) #must tune hyperparameters
        model.fit(trainX, trainy)

        #make a single prediciton
        pred = model.predict(np.asarray([testX]))

        return pred[0]


    def train_test_split(self, data, n_test):
        return data[:-n_test, :], data[-n_test:, :] #does this work for multivariate


    #21 samples per month
    def create_supervised_data(self, X_lag=63, y_lag=1):
        n_vars = 1 #Univariate
        #n_vars = 1 if type(data) is list else data.shape[1] # Use this when making multivariate able

        df = self.stock_data['Adj Close'].copy() #this will need to change for multivariate
        cols, names = list(), list()
	    # input sequence (t-n, ... t-1)
        for i in range(X_lag, 0, -1):
            cols.append(df.shift(i))
            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)] #Change this to better name the features

        # forecast sequence (t, t+1, ... t+n)
        for i in range(0, y_lag):
            cols.append(df.shift(-i))
            if i == 0:
                names += [('var%d(t)' % (j+1)) for j in range(n_vars)] # change this to name Adj Close or similar
            else:
                names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)] # change this to name Adj Close or similar

        agg = pd.concat(cols, axis=1)
        agg.columns = names
        agg.dropna(inplace=True) # may need a variable for dropna if some indicators have several na features
        return agg.values





